{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b84ab46",
   "metadata": {},
   "source": [
    "### Tools In Langchain\n",
    "1. How To Create Tools\n",
    "2. How to use built-in tools and toolkits\n",
    "3. How to use chat models to call tools\n",
    "4. How to pass tool outputs to chat models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca6f71",
   "metadata": {},
   "source": [
    "This @tool decorator is the simplest way to define a custom tool. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. Additionally, the decorator will use the function's docstring as the tool's description - so a docstring MUST be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79549ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## @tool decorator\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def division(a:int,b:int)->int:\n",
    "    \"\"\"Divide 2 number\"\"\"\n",
    "    return a/b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8025db20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division\n",
      "Divide 2 number\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(division.name)\n",
    "print(division.description)\n",
    "print(division.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbf0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## async implementation\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f160b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,List\n",
    "\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[int,\"A value\"],\n",
    "    b:Annotated[List[int],\"list of ints over which to take maximum\"]\n",
    ")->int:\n",
    "    \"\"\"Mulitply a by the maximum of b\"\"\"\n",
    "    return a* max(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52974572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'description': 'A value', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'list of ints over which to take maximum', 'items': {'type': 'integer'}, 'title': 'B', 'type': 'array'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply_by_max.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daca7c5",
   "metadata": {},
   "source": [
    "### Structured Tool\n",
    "The StructuredTool.from_function class method provides a bit more configurability than the @tool decorator, without requiring much additional code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00baaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator=StructuredTool.from_function(func=multiply,coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await calculator.ainvoke({\"a\": 2, \"b\": 5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500960bc",
   "metadata": {},
   "source": [
    "### Inbuilt Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73356501",
   "metadata": {},
   "source": [
    "### wikipedia Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab74a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max=500)\n",
    "tool=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool.invoke({\"query\":\"langchain\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8748b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b19bc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9c544be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    # include_answer=False,\n",
    "    # include_raw_content=False,\n",
    "    # include_images=False,\n",
    "    # include_image_descriptions=False,\n",
    "    # search_depth=\"basic\",\n",
    "    # time_range=\"day\",\n",
    "    # include_domains=None,\n",
    "    # exclude_domains=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7a35515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the recent ai news',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.wsj.com/tech/ai?gaa_at=eafs&gaa_n=ASWzDAhmJ_GQNq6W7fXWQIPczJ5rpf5czz9H4GBpXDhYX0Mm-TgaWUTHHwxB&gaa_ts=68a30010&gaa_sig=DmHwGbGlTN-xvBYj0IKljr_92NVR9QP43B5YAewKNmW2g1n347BGkcFB4Y2XC9AgF0CtkYlxJnpB-_KsiHY-tg%3D%3D',\n",
       "   'title': 'Artificial Intelligence - Latest AI News and Analysis - WSJ.com',\n",
       "   'content': 'The latest artificial intelligence news coverage focusing on the technology, tools and the companies building AI technology.',\n",
       "   'score': 0.67758125,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.crescendo.ai/news/latest-ai-news-and-updates',\n",
       "   'title': 'Latest AI Breakthroughs and News: June, July, August 2025',\n",
       "   'content': 'AI Boosts Early Detection of Diabetic Eye Disease ... Summary: New research shows AI can accurately screen for diabetic retinopathy—a leading cause of vision loss',\n",
       "   'score': 0.67527276,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.artificialintelligence-news.com/',\n",
       "   'title': 'AI News | Latest AI News, Analysis & Events',\n",
       "   'content': \"SoftBank chief: Forget AGI, ASI will be here within 10 years · NVIDIA aims to solve AI's issues with many languages · DeepSeek: The Chinese startup challenging\",\n",
       "   'score': 0.6504012,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.nbcnews.com/artificial-intelligence',\n",
       "   'title': 'Artificial intelligence - NBC News',\n",
       "   'content': \"The latest news and top stories on artificial intelligence, including AI chatbots like Microsoft's ChatGPT, Apple's AI Chatbot and Google's Bard.\",\n",
       "   'score': 0.6219319,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://aimagazine.com/',\n",
       "   'title': 'AI Magazine: Home of AI and Artificial Intelligence News',\n",
       "   'content': \"Zoom's Ben Neo shares how agentic AI is driving 80% autonomous query resolution by 2029, transforming customer service efficiency and satisfaction…\",\n",
       "   'score': 0.4751919,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.91,\n",
       " 'request_id': '5e0b138c-11cd-4af9-947c-f8b5fc54ec33'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke(\"What is the recent ai news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d349bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AgenticAIHindi\\.venv\\Lib\\site-packages\\langchain_community\\utilities\\arxiv.py:102: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  ).results()\n",
      "e:\\AgenticAIHindi\\.venv\\Lib\\site-packages\\feedparser\\html.py:152: DeprecationWarning: 'count' is passed as positional argument\n",
      "  data = re.sub(r'<!((?!DOCTYPE|--|\\[))', r'&lt;!\\1', data, re.IGNORECASE)\n",
      "e:\\AgenticAIHindi\\.venv\\Lib\\site-packages\\feedparser\\html.py:152: DeprecationWarning: 'count' is passed as positional argument\n",
      "  data = re.sub(r'<!((?!DOCTYPE|--|\\[))', r'&lt;!\\1', data, re.IGNORECASE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Published: 2023-08-02\\nTitle: Attention Is All You Need\\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\\nSummary: The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "tool=ArxivAPIWrapper()\n",
    "\n",
    "tool.run(\"1706.03762\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca77f5",
   "metadata": {},
   "source": [
    "### Call Tool With LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88207bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(wiki_tool.invoke({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd092828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    # include_answer=False,\n",
    "    # include_raw_content=False,\n",
    "    # include_images=False,\n",
    "    # include_image_descriptions=False,\n",
    "    # search_depth=\"basic\",\n",
    "    # time_range=\"day\",\n",
    "    # include_domains=None,\n",
    "    # exclude_domains=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8adb774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c3f1937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad39f352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6366835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fc11f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tavily_search'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eccafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki_tool,add,multiply,tavily_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d643b734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'e:\\\\AgenticAIHindi\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=100)),\n",
       " StructuredTool(name='add', description='Adds a and b.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000285E792D3A0>),\n",
       " StructuredTool(name='multiply', description='Multiplies a and b.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x00000285E786C4A0>),\n",
       " TavilySearch(max_results=5, topic='general', api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85acd91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000285980F3620>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000285982782F0>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm=init_chat_model(\"qwen/qwen3-32b\",model_provider=\"groq\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f11c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000285980F3620>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000285982782F0>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'Adds a and b.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiplies a and b.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'include_favicon': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': \"Determines whether to include favicon URLs for each search result.\\n        \\n        When enabled, each search result will include the website's favicon URL,\\n        which can be useful for:\\n        - Building rich UI interfaces with visual website indicators\\n        - Providing visual cues about the source's credibility or brand\\n        - Creating bookmark-like displays with recognizable site icons\\n        \\n        Set to True when creating user interfaces that benefit from visual branding\\n        or when favicon information enhances the user experience.\\n        \\n        Default is False to minimize response size and API usage.\\n        \"}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool=llm.bind_tools(tools)\n",
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77c9c9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is 2* 3\". Let me see. The multiplication symbol is a bit unclear, but I think they mean 2 multiplied by 3. Let me check the available tools. There\\'s a multiply function that takes two integers. So I should call multiply with a=2 and b=3. That should give the correct result of 6. I don\\'t need to use any other tools here since it\\'s a straightforward multiplication.\\n', 'tool_calls': [{'id': 'dbrg7ya4r', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 126, 'prompt_tokens': 2058, 'total_tokens': 2184, 'completion_time': 0.253766971, 'prompt_time': 0.12005249, 'queue_time': 0.060788129, 'total_time': 0.373819461}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--b38e54eb-77cf-474c-b4ec-78eb485730f0-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'dbrg7ya4r', 'type': 'tool_call'}] usage_metadata={'input_tokens': 2058, 'output_tokens': 126, 'total_tokens': 2184}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "query=\"What is 2* 3\"\n",
    "messages = [HumanMessage(query)]\n",
    "response=llm_with_tool.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00765560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, let\\'s see. The user asked \"What is 2* 3\". First, I need to figure out what they\\'re asking. The asterisk (*) is a multiplication symbol, so they want to know the product of 2 and 3. \\n\\nLooking at the tools provided, there\\'s a function called \"multiply\" which takes two integers as parameters. The description says it multiplies a and b. That\\'s exactly what I need here.\\n\\nSo, the parameters required are \"a\" and \"b\", both integers. The user\\'s input is 2 and 3. I should call the multiply function with a=2 and b=3. \\n\\nI need to make sure there are no other functions that could be used here. The \"add\" function is for addition, which isn\\'t needed here. The other functions like wikipedia and tavily_search are for more complex queries, not simple arithmetic. \\n\\nTherefore, the correct tool to use is the multiply function with the given parameters. The result should be 6.\\n', 'tool_calls': [{'id': '6qeka5s6c', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 239, 'prompt_tokens': 2058, 'total_tokens': 2297, 'completion_time': 0.776395807, 'prompt_time': 0.429693744, 'queue_time': 0.059521576, 'total_time': 1.206089551}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--63fcbbb6-7efc-45b6-8464-3b8af00ac37b-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '6qeka5s6c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2058, 'output_tokens': 239, 'total_tokens': 2297})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0957684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': '6qeka5s6c',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7a5a217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 2* 3', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='6', name='multiply', tool_call_id='dbrg7ya4r')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply,\"wikipedia\":wiki_tool,\"tavily_search\":tavily_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    \n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5962e2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='6', name='multiply', tool_call_id='6qeka5s6c')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bdd5659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='6', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 2* 3\". Let me see. The tools available include a multiply function. The parameters for multiply are a and b, both integers. So 2 multiplied by 3 would be 6. The answer is straightforward. I should call the multiply function with a=2 and b=3.\\n'}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 2068, 'total_tokens': 2144, 'completion_time': 0.149768476, 'prompt_time': 0.124041511, 'queue_time': 0.061685618, 'total_time': 0.273809987}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'finish_reason': 'stop', 'logprobs': None}, id='run--d3a09688-18dd-4a6a-8ec6-2b71d8c1493d-0', usage_metadata={'input_tokens': 2068, 'output_tokens': 76, 'total_tokens': 2144})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "430d240d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking two things here: what LangChain is and the result of 5 multiplied by 15. Let me break this down.\\n\\nFirst, for the definition of LangChain, I need to use the Wikipedia tool. The user might want a general explanation, so I\\'ll look up \"LangChain\" on Wikipedia. That should give an overview of what it is, its purpose, and maybe some key features. I should make sure to get the most accurate and up-to-date information from the Wikipedia entry.\\n\\nNext, the math problem: 5 times 15. This is straightforward arithmetic. The multiply function is available, so I can use that. The parameters are a=5 and b=15. The function should return 75. I need to call both functions and present the answers clearly.\\n\\nWait, the user might expect a quick answer for the multiplication, so using the multiply tool makes sense. For LangChain, since it\\'s a concept, Wikipedia is the right choice. Let me check if there are any other tools that might be better, but I think Wikipedia is suitable here. \\n\\nNo other parameters are needed for the Wikipedia query except the term \"LangChain\". For the multiplication, just the two numbers. I should structure the response with both answers once the tools provide the data.\\n', 'tool_calls': [{'id': 'pypqfsacv', 'function': {'arguments': '{\"query\":\"LangChain\"}', 'name': 'wikipedia'}, 'type': 'function'}, {'id': '1bd2kyw6k', 'function': {'arguments': '{\"a\":5,\"b\":15}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 320, 'prompt_tokens': 2064, 'total_tokens': 2384, 'completion_time': 0.748735493, 'prompt_time': 0.136872205, 'queue_time': 0.060083534, 'total_time': 0.885607698}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b31a2a90-cbac-4ed6-b8ed-1eb3f021a310-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'LangChain'}, 'id': 'pypqfsacv', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 5, 'b': 15}, 'id': '1bd2kyw6k', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2064, 'output_tokens': 320, 'total_tokens': 2384})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is langchain and what is 5*15?\"\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tool.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5979573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': 'LangChain'},\n",
       "  'id': 'pypqfsacv',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 5, 'b': 15},\n",
       "  'id': '1bd2kyw6k',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34cf0882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is langchain and what is 5*15?', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of ', name='wikipedia', tool_call_id='pypqfsacv'),\n",
       " ToolMessage(content='75', name='multiply', tool_call_id='1bd2kyw6k')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply,\"wikipedia\":wiki_tool,\"tavily_search\":tavily_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d777538",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm_with_tool.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8443c18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a software framework designed to simplify the integration of language models and other AI components into applications. It provides tools for building workflows, managing data, and creating interactive systems like chatbots or analysis tools. \\n\\nAdditionally, $5 \\\\times 15 = 75$.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0206fba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, let\\'s break down the user\\'s query. They asked three things: what is LangChain, calculate 5*15, and summarize recent AI news. \\n\\nFirst, for LangChain, I need to explain what it is. Since it\\'s a technical tool, maybe Wikipedia has a good overview. I should use the wikipedia function with \"LangChain\" as the query.\\n\\nNext, 5*15 is a math problem. The multiply function is perfect here. The parameters are a=5 and b=15. That should give the product, which is 75.\\n\\nLastly, summarizing recent AI news requires current information. The tavily_search function can fetch recent articles. I\\'ll set the query to \"recent AI news\", set the time_range to \"week\" to get the latest updates, and maybe include some domains like tech news sites. But since the user didn\\'t specify domains, I\\'ll leave include_domains as default. Search depth should be advanced to ensure comprehensive results.\\n\\nWait, do I need to exclude any domains? The user didn\\'t mention any, so exclude_domains can be default. Also, include_images and include_favicon aren\\'t necessary for a summary, so keep them as default. Topic should be \"general\" unless it\\'s finance or news-specific, but \"recent AI news\" might fit under \"general\". Hmm, maybe set topic to \"news\" for better results. Let me check the tool\\'s description. The topic parameter says to use \"news\" for politics, sports, or major events. AI news is more tech-related, so maybe \"general\" is still okay. I\\'ll go with \"general\" but set time_range to \"week\" to get recent articles.\\n\\nPutting it all together, three function calls: wikipedia for LangChain, multiply for 5*15, and tavily_search for recent AI news with time_range week.\\n', 'tool_calls': [{'id': 'qj7snxn3h', 'function': {'arguments': '{\"query\":\"LangChain\"}', 'name': 'wikipedia'}, 'type': 'function'}, {'id': 'nrfc9khvz', 'function': {'arguments': '{\"a\":5,\"b\":15}', 'name': 'multiply'}, 'type': 'function'}, {'id': '0t10pegj3', 'function': {'arguments': '{\"query\":\"recent AI news\",\"search_depth\":\"advanced\",\"time_range\":\"week\"}', 'name': 'tavily_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 474, 'prompt_tokens': 2070, 'total_tokens': 2544, 'completion_time': 1.479521767, 'prompt_time': 0.127585172, 'queue_time': 0.060314068, 'total_time': 1.607106939}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dfdcb96a-521d-4ccd-8a02-9e8553eb987d-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'LangChain'}, 'id': 'qj7snxn3h', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 5, 'b': 15}, 'id': 'nrfc9khvz', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'recent AI news', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': '0t10pegj3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2070, 'output_tokens': 474, 'total_tokens': 2544})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is langchain and what is 5*15 and summarize the recent AI news ?\"\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tool.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52b59815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': 'LangChain'},\n",
       "  'id': 'qj7snxn3h',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 5, 'b': 15},\n",
       "  'id': 'nrfc9khvz',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search',\n",
       "  'args': {'query': 'recent AI news',\n",
       "   'search_depth': 'advanced',\n",
       "   'time_range': 'week'},\n",
       "  'id': '0t10pegj3',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cfde5955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is langchain and what is 5*15 and summarize the recent AI news ?', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of ', name='wikipedia', tool_call_id='qj7snxn3h'),\n",
       " ToolMessage(content='75', name='multiply', tool_call_id='nrfc9khvz'),\n",
       " ToolMessage(content='{\"query\": \"recent AI news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://champaignmagazine.com/2025/08/17/ai-by-ai-weekly-top-5-august-11-17-2025/\", \"title\": \"AI by AI Weekly Top 5 (August 11 – 17, 2025) - Champaign Magazine\", \"content\": \"Date: August 17, 2025  \\\\nContext: Google’s Gemini AI introduced a new “Projects” feature that helps users organize long-term research tasks, similar to ChatGPT’s project mode.  \\\\nSignificance: This marks a shift toward AI as a productivity partner, enabling deeper research, better context retention, and more structured workflows.  \\\\nFeedback: Academics and professionals welcomed the feature, calling it a major boost for knowledge work.  \\\\nSource Links: [...] Date: August 11, 2025  \\\\nContext: OpenAI launched GPT-5 with major upgrades in reasoning and multimodal capabilities. However, the rollout triggered widespread user frustration due to model deprecations, broken workflows, and misleading performance charts.  \\\\nSignificance: One of the most controversial AI launches to date. Users lost access to older models without warning, leading to emotional backlash and broken systems. CEO Sam Altman issued a public apology and promised improvements. [...] Date: August 15, 2025  \\\\nContext: The Trump administration unveiled its AI Action Plan, featuring over 90 policies focused on global AI dominance, healthcare innovation, and international leadership. This includes greenlighting select AI chip exports to China with a 15% U.S. cut, amid bipartisan scrutiny.\", \"score\": 0.81595254, \"raw_content\": null}, {\"url\": \"https://techcrunch.com/category/artificial-intelligence/\", \"title\": \"AI News & Artificial Intelligence | TechCrunch\", \"content\": \"### Leaked Meta AI rules show chatbots were allowed to have romantic chats with kids\\\\n\\\\nMultiverse Computing founders\\\\n\\\\n### Buzzy AI startup Multiverse creates two of the smallest high-performing models ever\\\\n\\\\nGoogle Flight Deals\\\\n\\\\n### Google pushes AI into flight deals as antitrust scrutiny, competition heat up\\\\n\\\\nJoelle Pineau\\\\n\\\\n### Cohere hires long-time Meta research head Joelle Pineau as its chief AI officer\\\\n\\\\nBox CEO Aaron Levie on stage at TechCrunch Disrupt in San Francisco in 2019. [...] ### AI companion apps on track to pull in $120M in 2025\\\\n\\\\nDavid Petrou\\\\n\\\\n### Google vet raises $8M for Continua to bring AI agents to group chats\\\\n\\\\nAravind Srinivas, Co-Founder & CEO of Perplexity, speaks onstage during TechCrunch Disrupt 2024 in San Francisco, California.\\\\n\\\\n### Perplexity offers to buy Chrome for billions more than it’s raised\\\\n\\\\nAnthropic Co-Founder & CEO Dario Amodei speaks onstage during TechCrunch Disrupt 2023 at Moscone Center. [...] ### Anthropic nabs Humanloop team as competition for enterprise AI talent heats up\\\\n\\\\nNeoLogic, semiconductor, chips, data centers\\\\n\\\\n### NeoLogic wants to build more energy-efficient CPUs for AI data centers\\\\n\\\\nSam Altman\\\\n\\\\n### ChatGPT’s model picker is back, and it’s complicated\\\\n\\\\nAn illustration of Sam Altman in front of the OpenAI logo\\\\n\\\\n### Sam Altman, OpenAI will reportedly back a startup that takes on Musk’s Neuralink\\\\n\\\\nCharacter.AI screenshot\", \"score\": 0.7413937, \"raw_content\": null}, {\"url\": \"https://www.ibm.com/think\", \"title\": \"Think - IBM\", \"content\": \"15 Aug\\\\n\\\\nThe baby in the machine: How filmmakers are reimagining cinema with AI\\\\n\\\\n15 Aug\\\\n\\\\nHuman resources\\\\n\\\\nThe new state of HR: Pressures, systems and skills\\\\n\\\\n14 Aug\\\\n\\\\nTalent management\\\\n\\\\nWhy data and AI literacy are HR\\'s new superpowers\\\\n\\\\n14 Aug\\\\n\\\\nObservability\\\\n\\\\nWhy observability is essential for AI agents\\\\n\\\\n12 Aug\\\\n\\\\n## Meta’s superintelligence lab turns speculation into engineering [...] Meta is pouring billions into a new research lab to develop an AI it says could rival or exceed human abilities across disciplines. Read here.\\\\n\\\\nCybersecurity\\\\n\\\\n30 Jul\\\\n\\\\n2025 Cost of a Data Breach Report: Navigating the AI rush without sidelining security\\\\n\\\\nLimor Kessem\\\\n\\\\nMost popular [...] What’s in the 2025 report — and what to know about security\\\\n\\\\n### Artificial intelligence\\\\n\\\\n## In case you missed it\\\\n\\\\nOur most popular stories in 2025 so far\\\\n\\\\n## AI for everyday life\\\\n\\\\nHow AI is enhancing the ordinary\\\\n\\\\n## Podcasts\\\\n\\\\nHear the latest in AI, new tech, business transformation and more from various experts.\\\\n\\\\nMixture of experts podcast artwork\\\\nTransformers podcast artwork\\\\nSmart talks podcast artwork\\\\nAI in action podcast artwork\\\\n\\\\n## Videos\", \"score\": 0.65914243, \"raw_content\": null}, {\"url\": \"https://vavoza.com/20-technology-news-updates-and-ai-developments-this-week-in-august-2025/\", \"title\": \"20 Technology News, Updates, and AI Developments This Week In ...\", \"content\": \"Picture of Vavoza Team\\\\n\\\\n# 20 Technology News and AI Developments This Week In August 2025\\\\n\\\\nHere are the top 20 technology news, updates, AI developments, and trending tools this week in August 2025:\\\\n\\\\n## This Week’s Latest Technology and AI News\\\\n\\\\n## This Week’s Trending AI Tools\\\\n\\\\nYou may also want to check out some of our other recent updates.\\\\n\\\\nSubscribe to Vavoza Insider to access the latest business and marketing insights, news, and trends daily! 🗞️\\\\n\\\\n## Share With Your Audience\\\\n\\\\nVavoza Insider\", \"score\": 0.64880073, \"raw_content\": null}, {\"url\": \"https://www.cnbc.com/2025/08/18/openai-sam-altman-warns-ai-market-is-in-a-bubble.html\", \"title\": \"OpenAI\\'s Sam Altman says AI market is in a bubble - CNBC\", \"content\": \"Earlier this month, Altman told CNBC that OpenAI\\'s annual recurring revenue is on track to pass $20 billion this year, but that despite that, it remains unprofitable.\\\\n\\\\nThe release of OpenAI\\'s latest GPT-5 AI model earlier this month had also been rocky, with some critics complaining that it had a less intuitive feel. This resulted in the company restoring access to legacy GPT-4 models for paying customers. [...] In The Verge article on Friday, the OpenAI CEO also discussed OpenAI\\'s expansion into consumer hardware, brain-computer interfaces and social media.\\\\n\\\\nAltman also said that he expects OpenAI to spend trillions of dollars on its data center buildout in the \\\\\"not very distant future,\\\\\"  and signaled that the company would be interested in buying Chrome if the U.S. government were to force Google to sell it. [...] Many Fears of an AI bubble had hit a fever pitch at the start of this year when Chinese start-up DeepSeek released a competitive reasoning model. The company claimed one version of its advanced large language models had been trained for under $6 million, a fraction of the billions being spent by U.S. AI market leaders like OpenAI, though these claims were also been met with some skepticism.\", \"score\": 0.6052631, \"raw_content\": null}], \"response_time\": 2.07, \"request_id\": \"65558a8b-db98-4856-949d-410e4cab0f4c\"}', name='tavily_search', tool_call_id='0t10pegj3')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply,\"wikipedia\":wiki_tool,\"tavily_search\":tavily_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf0f8136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. **LangChain**: According to Wikipedia, *LangChain* is a software framework designed to facilitate the integration of language models and other AI components into applications. It provides tools for handling prompts, managing memory, and connecting to external data sources, making it easier to build AI-driven workflows.\\n\\n2. **5*15**: The result of multiplying 5 by 15 is **75**.\\n\\n3. **Recent AI News Summary**:\\n   - **Google\\'s Gemini AI** introduced a \"Projects\" feature for organizing long-term research tasks, positioning AI as a productivity partner.\\n   - **OpenAI\\'s GPT-5** launched with improved reasoning but faced backlash for deprecating older models abruptly, causing user frustration.\\n   - The **Trump administration** unveiled an AI Action Plan with 90+ policies, including relaxed AI chip export rules to China.\\n   - **Meta** is investing in a \"superintelligence lab\" to develop AI rivaling human capabilities.\\n   - **Anthropic** and startups like NeoLogic are advancing AI research, while concerns about an \"AI market bubble\" grow (OpenAI\\'s Sam Altman called it a \"speculative frenzy\").\\n   - **AI ethics debates** intensified, including Meta allowing chatbots to engage in romantic conversations with minors.\\n\\nFor deeper details, refer to [TechCrunch](https://techcrunch.com) or [IBM Think](https://www.ibm.com/think) for ongoing coverage.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=llm_with_tool.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d31ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAIHindi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
